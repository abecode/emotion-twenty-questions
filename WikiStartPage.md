# Introduction #

  * [Frequently asked questions](FAQ.md).
  * [news](news.md)
  * [Rules of EMO20Q](Rules.md).
  * [Ejabberd (server) configuration](EjabberdConfiguration.md).
  * [client  (user interface) configuration](ClientConfiguration.md)
  * [Editing the Wiki](https://code.google.com/p/emotion-twenty-questions/w/list)

# [Data](Data.md) #

The data that is available comes in several formats.
  * First, there is the raw chat files which is automatically logged by the [ejabberd server](EjabberdConfiguration.md) and then anonymized with perl scripts.  The up-to-date location of this data is [here in svn](https://code.google.com/p/emotion-twenty-questions/source/browse/trunk#trunk%2Fanon_chatlogs).  This data is useful for NLP tasks and analyzing low level user behavior (e.g., time stamps, small talk between questions and matches)
  * Then, we have manually annotated data.  This is manually formatted into question-answer turns and annotated with semantic information about the question and answer's meaning.  The up-to-date location of this data is The up-to-date location of this data is [here in svn](https://code.google.com/p/emotion-twenty-questions/source/browse/trunk#trunk%2Fannotate)
  * We're trying to keep snapshots of the data from various milestones so that earlier experiments can be re-run.  They will be stored as [svn branches](https://code.google.com/p/emotion-twenty-questions/source/browse/branches).
  * We also want to provide data that is annotated and/or conveniently reformatted.  These may be available in the [downloads page](https://code.google.com/p/emotion-twenty-questions/downloads/list) or generated by scripts.

Please see [Data](Data.md) for more details.

# Development #

The software development for emo20q has several aims and directions:
  * First, to enable the collection of human-human data.  Currently, we have focused on dyadic (two-person) text chat data, but other modalities are possible and have been tested on a small scale.  In particular, multi-party, voice-based EMO20Q has been played on road trips and at social gatherings.  Recording and analyzing these different modalities are areas for future work.
  * Secondly, to test the computational models of user behavior though simulation of EMO20Q players in virtual agents (i.e., Turing-style tests).  Currently, we have text/chat and voice/phone-based agents for the questioner role.  Future work for the questioner includes better understanding of gradient/fuzzy answers to yes/no questions. Implementing the answerer role is still an open area.
  * Third, to make the data and findings more accessible to those who may be interested in or who may benefit from this work.  This involves taking academic code and porting it to publicly available and interactive websites and voiced-based portals.  It also involves packaging data so that EMO20Q data can be used in a way that keeps the players' identities private.  Another way to make the project more accessible is by releasing implementations in different languages and formats.  While text files and matlab are useful to engineering researchers, programmers may prefer databases and open api's, educators might prefer interactive websites, and psychologists may want data that can be accessed with statistics toolboxes.
Our software development framework is very laissez-faire.  We don't have one specific programming language or operating system.  We try to follow an [agile/XP](UserStories.md) style of development, which means that we try to release demos and code as soon as possible after verifying that the data is anonymized and the code is secure. In particular, we try to make data and demos available prior to publication.

# [Publications](Publications.md) #

  * [A Sequential Bayesian Dialog Agent for Computational Ethnography (Interspeech 2012)](http://emotion-twenty-questions.googlecode.com/svn/trunk/writing/interspeech2012_sequentialBayesianDialogAgent/emo20q_naive_bayes.pdf)
  * [Emotion Twenty Questions: Toward a Crowd-Sourced Theory of Emotions (ACII 2011)](http://sail.usc.edu/aigaion2/index.php/publications/show/473)
  * [Determining What Questions to Ask, with the Help of Spectral Graph Theory (Interspeech 2011)](http://sail.usc.edu/aigaion2/index.php/publications/show/450)
  * Abe Kazemzadeh's [thesis proposal](http://sail.usc.edu/~kazemzad/proposal_v2.pdf) and shorter [precis (ACII 2011)](http://sail.usc.edu/~kazemzad/precis.pdf)
  * EMO20Q Questioner Agent demo (ACII 2011)

# Research Topics #

## Graphical Models/Graph Theory ##

One paradigm for studying this data is to consider questions as descriptions that pertain to certain emotions.  Seen in this way, we can say that a description/question is linked to an emotion if a player has answered yes about the emotion when asked the question.  Here is a [visualization of the emo20q graph](http://sail.usc.edu/~kazemzad/emo20q/prefuseDemo/) using the open source [prefuse visualization software](http://prefuse.org)

## Game Theory/User Behavior Analysis ##

EMO20Q is first and foremost a fun game.  Why is it fun?  I think it's fun because it's difficult, but not to hard to learn to play, because you play with other people, and because different people have different styles of playing.  The idea of a playing style or strategy is one way to study subject-specific behavior.

## Natural language processing ##

EMO20Q is a game that is played using natural language.  Because it is played over chat, it has much in common with recent trends communication trends like sms/im.  Because emotions are very personal, the way people describe emotions in natural language is an ideal testbed to study subjective information, which which has become a hot topic (sentiment analysis and opinion mining--note: I do not like the term "sentiment" in this context.  I think it should be called "utility" to borrow from extensive research in economics).

## Psychology/Neurolinguistics/Philosophy of Language ##

One of the reasons that EMO20Q is difficult is that language and emotions may be processed in different but connected parts of the brain.  First, much of what we talk about is sensed from vision, hearing, or manual manipulation.  However, emotions are not physical objects that we can see, hear, or feel manually,  but rather internal states that we feel internally and infer from behavior in various situations, so distinguishing and naming emotions is indirect and subjective. Also, emotions are biological mechanisms that humans share with other animals, but language, as a conventional symbolic system, is distinctly human, so it can be difficult to use language to describe an older system which it build on top of.

# [Editing the Wiki](https://code.google.com/p/emotion-twenty-questions/w/list) #

  * The wiki pages can be edited [at the wiki page index](https://code.google.com/p/emotion-twenty-questions/w/list)